apiVersion: v1
kind: ConfigMap
metadata:
  name: oap-config
  namespace: {{.Release.Namespace}}
data:
  envoy.yaml: |
    admin:
      access_log_path: /tmp/admin_access.log
      address:
        socket_address: { address: 0.0.0.0, port_value: 50001 }
    static_resources:
      listeners:
      - name: es_listener
        address:
          socket_address: { address: 0.0.0.0, port_value: 9200 }
        filter_chains:
        - filters:
          - name: envoy.http_connection_manager
            config:
              stat_prefix: elasticsearch
              codec_type: AUTO
              route_config:
                name: local_route
                request_headers_to_add:
                - header:
                    key: tcc-route-target
                    value: elasticsearch
                {{- if .Values.token }}
                - header:
                    key: Authorization
                    value: "Bearer $token"
                {{- end }}
                virtual_hosts:
                - name: local_service
                  domains: ['*']
                  routes:
                  - match: { prefix: '/' }
                    route: { cluster: elasticsearch }
              http_filters:
              - name: envoy.router
      - name: oap_tcc_listener
        address:
          socket_address: { address: 0.0.0.0, port_value: 21800 }
        filter_chains:
        - filters:
          - name: envoy.http_connection_manager
            config:
              stat_prefix: oap_tcc
              codec_type: AUTO
              route_config:
                name: local_route
                request_headers_to_add:
                {{- if .Values.token }}
                - header:
                    key: Authorization
                    value: "Bearer $token"
                {{- end }}
                virtual_hosts:
                - name: local_service
                  domains: ['*']
                  routes:
                  - match: { prefix: '/' }
                    route: { cluster: oap-tcc }
              http_filters:
              - name: envoy.router
      {{- if .Values.externalServices.metadata.enabled }}
      - name: ex_metadata_listener
        address:
          socket_address: { address: 0.0.0.0, port_value: 9080 }
        filter_chains:
        - filters:
          - name: envoy.http_connection_manager
            config:
              stat_prefix: ex_metadata
              codec_type: AUTO
              route_config:
                name: local_route
                request_headers_to_add:
                - header:
                    key: Authorization
                    value: "Bearer $token"
                virtual_hosts:
                - name: local_service
                  domains: ['*']
                  routes:
                  - match: { prefix: '/' }
                    route: { cluster: oap-tcc }
              http_filters:
              - name: envoy.router
      {{- end }}
      {{- if .Values.externalServices.configuration.enabled }}
      - name: ex_configuraion_listener
        address:
          socket_address: { address: 0.0.0.0, port_value: 9081 }
        filter_chains:
        - filters:
          - name: envoy.http_connection_manager
            config:
              stat_prefix: ex_configuration
              codec_type: AUTO
              route_config:
                name: local_route
                request_headers_to_add:
                - header:
                    key: Authorization
                    value: "Bearer $token"
                virtual_hosts:
                - name: local_service
                  domains: ['*']
                  routes:
                  - match: { prefix: '/' }
                    route: { cluster: oap-tcc }
              http_filters:
              - name: envoy.router
      {{- end }}
      clusters:
      - name: elasticsearch
        connect_timeout: 5s
        type: STRICT_DNS
        lb_policy: ROUND_ROBIN
        {{- if .Values.global.elasticsearch.ssl.enabled }}
        tls_context: {}
        {{- end }}
        hosts:
        - socket_address:
            address: {{ .Values.elasticsearch.host }}
            port_value: {{ .Values.elasticsearch.port }}
      - name: oap-tcc
        connect_timeout: 5s
        type: STRICT_DNS
        lb_policy: ROUND_ROBIN
        tls_context: {}
        http2_protocol_options: {}
        hosts:
        - socket_address:
            address: {{ .Values.global.tcc.host }}
            port_value: {{ .Values.global.tcc.port }}
  application.yml: |-
    cluster:
      kubernetes:
        watchTimeoutSeconds: 60
        namespace: {{.Release.Namespace}}
        labelSelector: app=oap
        uidEnvName: SKYWALKING_COLLECTOR_UID
    core:
      default:
        # Mixed: Receive agent data, Level 1 aggregate, Level 2 aggregate
        # Receiver: Receive agent data, Level 1 aggregate
        # Aggregator: Level 2 aggregate
        role: ${SW_CORE_ROLE:Mixed} # Mixed/Receiver/Aggregator
        restHost: ${SW_CORE_REST_HOST:0.0.0.0}
        restPort: ${SW_CORE_REST_PORT:12800}
        restContextPath: ${SW_CORE_REST_CONTEXT_PATH:/}
        gRPCHost: ${SW_CORE_GRPC_HOST:0.0.0.0}
        gRPCPort: ${SW_CORE_GRPC_PORT:11800}
        downsampling:
          - Hour
          - Day
        persistentPeriod: 10
        # Set a timeout on metrics data. After the timeout has expired, the metrics data will automatically be deleted.
        # User zone SPM doesn't do delete, TCC SPM do that centrally.
        enableDataKeeperExecutor: ${SW_CORE_ENABLE_DATA_KEEPER_EXECUTOR:false} # Turn it off then automatically metrics data delete will be close.
        recordDataTTL: ${SW_CORE_RECORD_DATA_TTL:90} # Unit is minute
        minuteMetricsDataTTL: ${SW_CORE_MINUTE_METRIC_DATA_TTL:90} # Unit is minute
        hourMetricsDataTTL: ${SW_CORE_HOUR_METRIC_DATA_TTL:36} # Unit is hour
        dayMetricsDataTTL: ${SW_CORE_DAY_METRIC_DATA_TTL:45} # Unit is day
        monthMetricsDataTTL: ${SW_CORE_MONTH_METRIC_DATA_TTL:18} # Unit is month
        # Cache metric data for 1 minute to reduce database queries, and if the OAP cluster changes within that minute,
        # the metrics may not be accurate within that minute.
        enableDatabaseSession: ${SW_CORE_ENABLE_DATABASE_SESSION:true}
        topNReportPeriod: ${SW_CORE_TOPN_REPORT_PERIOD:10} # top_n record worker report cycle, unit is minute
    storage:
      {{- if .Values.externalServices.metadata.enabled }}
      tsb-es:
        tsbHost: ${SW_TSB_HOST:localhost}
        tsbPort: ${SW_TSB_HOST:9080}
      {{- else }}
      elasticsearch:
      {{- end }}
        nameSpace: ${SW_NAMESPACE:""}
        clusterNodes: ${SW_STORAGE_ES_CLUSTER_NODES:localhost:9200}
        user: ${SW_ES_USER:"{{ .Values.global.elasticsearch.user }}"}
        password: ${SW_ES_PASSWORD:"{{ .Values.global.elasticsearch.password }}"}
        indexShardsNumber: ${SW_STORAGE_ES_INDEX_SHARDS_NUMBER:2}
        indexReplicasNumber: ${SW_STORAGE_ES_INDEX_REPLICAS_NUMBER:0}
        enablePackedDownsampling: {{ .Values.enabledPackedDownsampling }}
        dayStep: {{ .Values.dayStep }}
        # Those data TTL settings will override the same settings in core module.
        recordDataTTL: ${SW_STORAGE_ES_RECORD_DATA_TTL:7} # Unit is day
        otherMetricsDataTTL: ${SW_STORAGE_ES_OTHER_METRIC_DATA_TTL:45} # Unit is day
        monthMetricsDataTTL: ${SW_STORAGE_ES_MONTH_METRIC_DATA_TTL:18} # Unit is month
        # Batch process setting, refer to https://www.elastic.co/guide/en/elasticsearch/client/java-api/5.5/java-docs-bulk-processor.html
        bulkActions: ${SW_STORAGE_ES_BULK_ACTIONS:2000} # Execute the bulk every 2000 requests
        flushInterval: ${SW_STORAGE_ES_FLUSH_INTERVAL:10} # flush the bulk every 10 seconds whatever the number of requests
        concurrentRequests: ${SW_STORAGE_ES_CONCURRENT_REQUESTS:2} # the number of concurrent requests
        resultWindowMaxSize: ${SW_STORAGE_ES_QUERY_MAX_WINDOW_SIZE:10000}
        metadataQueryMaxSize: ${SW_STORAGE_ES_QUERY_MAX_SIZE:5000}
        segmentQueryMaxSize: ${SW_STORAGE_ES_QUERY_SEGMENT_SIZE:200}
        advanced: ${SW_STORAGE_ES_ADVANCED:""}
    receiver-sharing-server:
      default:
    receiver-register:
      default:
    service-mesh:
      default:
        bufferPath: ${SW_SERVICE_MESH_BUFFER_PATH:../mesh-buffer/}  # Path to trace buffer files, suggest to use absolute path
        bufferOffsetMaxFileSize: ${SW_SERVICE_MESH_OFFSET_MAX_FILE_SIZE:100} # Unit is MB
        bufferDataMaxFileSize: ${SW_SERVICE_MESH_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB
        bufferFileCleanWhenRestart: ${SW_SERVICE_MESH_BUFFER_FILE_CLEAN_WHEN_RESTART:false}
    spm-envoy-metric:
      default:
        enableMetricsService: ${SW_ENABLE_ENVOY_METRICS_SERIVCE:true}
        enableALS: ${SW_ENABLE_ENVOY_ALS:true}
        alsHTTPAnalysis: {{ .Values.analysis }}
        cluster: {{ .Values.global.tcc.cluster }}
        env: {{ .Values.global.tcc.environment }}
        regAgentHost: ${SW_ENVOY_METRIC_ALS_REG_AGENT_HOST:tsbd}
        regAgentPort: ${SW_ENVOY_METRIC_ALS_REG_AGENT_PORT:9080}
    query:
      graphql:
        path: ${SW_QUERY_GRAPHQL_PATH:/graphql}
    alarm:
      default:
    telemetry:
      prometheus:
        host: ${SW_TELEMETRY_PROMETHEUS_HOST:0.0.0.0}
        port: ${SW_TELEMETRY_PROMETHEUS_PORT:1234}
    configuration:
      {{- if .Values.externalServices.configuration.enabled }}
      grpc:
        host: ${SW_CONFIGURATION_GRPC_HOST:localhost}
        port: ${SW_CONFIGURATION_GRPC_PORT:9081}
        period: {{ .Values.externalServices.configuration.period }}
        clusterName: "{{ .Values.externalServices.configuration.clusterName }}"
      {{- else }}
      none:
      {{- end }}
    exporter:
      user2central:
        targetHost: ${SW_EXPORTER_GRPC_HOST:localhost}
        targetPort: ${SW_EXPORTER_GRPC_PORT:21800}
        bufferPath: ${SW_EXPORTER_BUFFER_PATH:../exporter-buffer/}  # Path to trace buffer files, suggest to use absolute path
        bufferOffsetMaxFileSize: ${SW_EXPORTER_BUFFER_OFFSET_MAX_FILE_SIZE:100} # Unit is MB
        bufferDataMaxFileSize: ${SW_EXPORTER_BUFFER_DATA_MAX_FILE_SIZE:500} # Unit is MB
        bufferFileCleanWhenRestart: ${SW_EXPORTER_BUFFER_FILE_CLEAN_WHEN_RESTART:false}

  log4j2.xml: |-
    <Configuration status="WARN">
        <Appenders>
            <Console name="Console" target="SYSTEM_OUT">
                <PatternLayout charset="UTF-8" pattern="%d - %c -%-4r [%t] %-5p %x - %m%n"/>
            </Console>
        </Appenders>
        <Loggers>
            <logger name="org.eclipse.jetty" level="INFO"/>
            <logger name="org.apache.zookeeper" level="INFO"/>
            <logger name="org.elasticsearch.common.network.IfConfig" level="INFO"/>
            <logger name="io.grpc.netty" level="INFO"/>
            <logger name="org.apache.skywalking.oap.server.receiver.istio.telemetry" level="INFO"/>
            <!-- uncomment following line when need to debug ALS raw data
            <logger name="io.tetrate.spm.user.receiver.envoy" level="DEBUG"/>
            -->
            <Root level="{{ default "WARN" .Values.logLevel }}">
                <AppenderRef ref="Console"/>
            </Root>
        </Loggers>
    </Configuration>

  official_analysis.oal: |-

    // Service scope metric
    service_heatmap = from(Service.latency).thermodynamic(100, 20);
    service_resp_time = from(Service.latency).longAvg();
    service_sla = from(Service.*).percent(status == true);
    service_cpm = from(Service.*).cpm();
    service_apdex = from(Service.latency).apdex(name, status);
    service_percentile = from(Service.latency).percentile(10); // Multiple values including p50, p75, p90, p95, p99

    service_status_code = from(Service.*).statusCode(responseCode);
    service_2xx = from(Service.*).filter(responseCode >= 200).filter(responseCode < 400).cpm();
    service_4xx = from(Service.*).filter(responseCode >= 400).filter(responseCode < 500).cpm();
    service_5xx = from(Service.*).filter(responseCode >= 500).cpm();

    // Service Instance relation scope metrics for topology
    service_instance_relation_client_cpm = from(ServiceInstanceRelation.*).filter(detectPoint == DetectPoint.CLIENT).cpm();
    service_instance_relation_server_cpm = from(ServiceInstanceRelation.*).filter(detectPoint == DetectPoint.SERVER).cpm();
    service_instance_relation_client_call_sla = from(ServiceInstanceRelation.*).filter(detectPoint == DetectPoint.CLIENT).percent(status == true);
    service_instance_relation_server_call_sla = from(ServiceInstanceRelation.*).filter(detectPoint == DetectPoint.SERVER).percent(status == true);
    service_instance_relation_client_resp_time = from(ServiceInstanceRelation.latency).filter(detectPoint == DetectPoint.CLIENT).longAvg();
    service_instance_relation_server_resp_time = from(ServiceInstanceRelation.latency).filter(detectPoint == DetectPoint.SERVER).longAvg();
    service_instance_relation_client_percentile = from(ServiceInstanceRelation.latency).filter(detectPoint == DetectPoint.CLIENT).percentile(10); // Multiple values including p50, p75, p90, p95, p99
    service_instance_relation_server_percentile = from(ServiceInstanceRelation.latency).filter(detectPoint == DetectPoint.SERVER).percentile(10); // Multiple values including p50, p75, p90, p95, p99

    // Service Instance Scope metric
    service_instance_sla = from(ServiceInstance.*).percent(status == true);
    service_instance_resp_time= from(ServiceInstance.latency).longAvg();
    service_instance_cpm = from(ServiceInstance.*).cpm();
    service_instance_apdex = from(ServiceInstance.latency).apdex(name, status);
    service_instance_percentile = from(ServiceInstance.latency).percentile(10); // Multiple values including p50, p75, p90, p95, p99

    service_instance_status_code = from(ServiceInstance.*).statusCode(responseCode);
    service_instance_2xx = from(ServiceInstance.*).filter(responseCode >= 200).filter(responseCode < 400).cpm();
    service_instance_4xx = from(ServiceInstance.*).filter(responseCode >= 400).filter(responseCode < 500).cpm();
    service_instance_5xx = from(ServiceInstance.*).filter(responseCode >= 500).cpm();

    // Envoy instance metric
    // envoy_heap_memory_max_used = from(EnvoyInstanceMetric.value).filter(metricName == "server.memory_heap_size").maxDouble();
    // envoy_total_connections_used = from(EnvoyInstanceMetric.value).filter(metricName == "server.total_connections").maxDouble();
    // envoy_parent_connections_used = from(EnvoyInstanceMetric.value).filter(metricName == "server.parent_connections").maxDouble();

    // Service relation scope metric for topology
    service_relation_client_cpm = from(ServiceRelation.*).filter(detectPoint == DetectPoint.CLIENT).cpm();
    service_relation_server_cpm = from(ServiceRelation.*).filter(detectPoint == DetectPoint.SERVER).cpm();
    service_relation_client_call_sla = from(ServiceRelation.*).filter(detectPoint == DetectPoint.CLIENT).percent(status == true);
    service_relation_server_call_sla = from(ServiceRelation.*).filter(detectPoint == DetectPoint.SERVER).percent(status == true);
    service_relation_client_resp_time = from(ServiceRelation.latency).filter(detectPoint == DetectPoint.CLIENT).longAvg();
    service_relation_server_resp_time = from(ServiceRelation.latency).filter(detectPoint == DetectPoint.SERVER).longAvg();

    // Endpoint scope metric
    endpoint_cpm = from(Endpoint.*).cpm();
    endpoint_avg = from(Endpoint.latency).longAvg();
    endpoint_sla = from(Endpoint.*).percent(status == true);
    endpoint_apdex = from(Endpoint.latency).apdex(name, status);
    endpoint_percentile = from(Endpoint.latency).percentile(10); // Multiple values including p50, p75, p90, p95, p99

    endpoint_status_code = from(Endpoint.*).statusCode(responseCode);
    endpoint_2xx = from(Endpoint.*).filter(responseCode >= 200).filter(responseCode < 400).cpm();
    endpoint_4xx = from(Endpoint.*).filter(responseCode >= 400).filter(responseCode < 500).cpm();
    endpoint_5xx = from(Endpoint.*).filter(responseCode >= 500).cpm();

    // Disable unnecessary hard core sources
    /////////
    // disable(service_relation_server_side);
    // disable(service_relation_client_side);
    disable(segment);
    disable(endpoint_relation_server_side);
    disable(top_n_database_statement);
    disable(zipkin_span);
    disable(jaeger_span);
  alarm-settings.yml: |-
    rules:
      # Rule unique name, must be ended with `_rule`.
      service_resp_time_rule:
        metrics-name: service_resp_time
        op: ">"
        threshold: 1000
        period: 10
        count: 3
        silence-period: 5
        message: Response time of service {name} is more than 1000ms in 3 minutes of last 10 minutes.
      service_sla_rule:
        # Metrics value need to be long, double or int
        metrics-name: service_sla
        op: "<"
        threshold: 8000
        # The length of time to evaluate the metrics
        period: 10
        # How many times after the metrics match the condition, will trigger alarm
        count: 2
        # How many times of checks, the alarm keeps silence after alarm triggered, default as same as period.
        silence-period: 3
        message: Successful rate of service {name} is lower than 80% in 2 minutes of last 10 minutes
      service_p90_sla_rule:
        # Metrics value need to be long, double or int
        metrics-name: service_p90
        op: ">"
        threshold: 1000
        period: 10
        count: 3
        silence-period: 5
        message: 90% response time of service {name} is more than 1000ms in 3 minutes of last 10 minutes
      service_instance_resp_time_rule:
        metrics-name: service_instance_resp_time
        op: ">"
        threshold: 1000
        period: 10
        count: 2
        silence-period: 5
        message: Response time of service instance {name} is more than 1000ms in 2 minutes of last 10 minutes
    webhooks:
      {{ .Values.externalServices.webhook.uri }}
